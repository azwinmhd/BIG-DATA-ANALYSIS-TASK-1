# BIG-DATA-ANALYSIS-TASK-1
NAME: AZWIN MUHAMMED KK 
COMPANY: CODTECH IT SOLUTIONS
ID: CT08EQY
DOMAIN: DATA ANALYTICS
DURATION: December 20th, 2024 to January 20th, 2025 
MENTOR: SRAVANI GOUNI

Description of Task-1:
In this analysis we need to install necessary libraries like pyspark,jdk,spark. And setting up environment variables and initially SparkSession.
I have took the titanic dataset from the drive imported by google colab. We can replace the dataset with our path.
Next read the dataset and also give conditions like sucess or error in the loading of the datas. In schema root we will be able to see the columns types.
We can load the data on our way of analysis like printing first five rows, number of passengers etc. ALso we can give filtering, adding new column based on our needs.
Finally we can stop the spark session by giving the command. This is the overlay of the program.
Big data is very huge and complex it can be of any structure based on the datas. As before, we cannot use traditional method for big data now, there are tons of datas generated everyday. That's why we use big tools like Apache Spark and Hadoop. These are very helpful for data analysts for doing their tasks. In this task i have intsalled spark, java and pyspark also very important to setup the environment variables in your system. You can use Ai tools for the guide also youtube videos. 

Output of Dataset:
![Image](https://github.com/user-attachments/assets/2e916753-f8f2-4569-83ba-c187f071ef4e)
![Image](https://github.com/user-attachments/assets/a786764f-ec82-4bf9-aa6c-db24cb610d3a)




